{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9475ccc",
   "metadata": {},
   "source": [
    "<h2>Business Understanding</h2>\n",
    "Before trying to build a model, it is crucial to first understand the business need behind the solution that we will attempt to solve.\n",
    "\n",
    "<h4>Assess Situation:</h4>\n",
    "The dataset contains the scores of 120 patients on the 17 essential symptoms psychiatrists use to diagnose the described disorders, which are Bipolar Disorder Type-1, Bipolar Disorder Type-2 and Major Depressive Disorder. The behavioral symptoms are considered according to the levels of: Sadness, Exhaustness, Euphoric, Sleep disorder, Mood swings, Suicidal thoughts, Anorexia, Anxiety, Try-explaining, Nervous breakdown, Ignore & Move-on, Admitting mistakes, Overthinking, Aggressive response, Optimism, Sexual activity, and Concentration. \n",
    "<br><br>\n",
    "The Normal category refer to the individuals using therapy time for specialized counseling, personal development, and life skill enrichments. \n",
    "While such individuals may also have minor mental problems, they differ from those suffering from Major Depressive Disorder and Bipolar Disorder.\n",
    "\n",
    "<h4>Business Objectives:</h4>\n",
    " Determining the likelihood that a potential patient has a mental disorder based on the answers to the provided 17 essential symptoms \n",
    " to utilize the tool in the future if performance is satisfactory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4398de",
   "metadata": {},
   "source": [
    "<h2>Data Understanding</h2>\n",
    "Examining the data before we prepare it for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe6ad3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url='Dataset-Mental-Disorders.csv'\n",
    "df=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af68211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient Number</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Euphoric</th>\n",
       "      <th>Exhausted</th>\n",
       "      <th>Sleep dissorder</th>\n",
       "      <th>Mood Swing</th>\n",
       "      <th>Suicidal thoughts</th>\n",
       "      <th>Anorxia</th>\n",
       "      <th>Authority Respect</th>\n",
       "      <th>Try-Explanation</th>\n",
       "      <th>Aggressive Response</th>\n",
       "      <th>Ignore &amp; Move-On</th>\n",
       "      <th>Nervous Break-down</th>\n",
       "      <th>Admit Mistakes</th>\n",
       "      <th>Overthinking</th>\n",
       "      <th>Sexual Activity</th>\n",
       "      <th>Concentration</th>\n",
       "      <th>Optimisim</th>\n",
       "      <th>Expert Diagnose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patiant-01</td>\n",
       "      <td>Usually</td>\n",
       "      <td>Seldom</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>3 From 10</td>\n",
       "      <td>3 From 10</td>\n",
       "      <td>4 From 10</td>\n",
       "      <td>Bipolar Type-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Patiant-02</td>\n",
       "      <td>Usually</td>\n",
       "      <td>Seldom</td>\n",
       "      <td>Usually</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>4 From 10</td>\n",
       "      <td>2 From 10</td>\n",
       "      <td>5 From 10</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patiant-03</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Most-Often</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>6 From 10</td>\n",
       "      <td>5 From 10</td>\n",
       "      <td>7 From 10</td>\n",
       "      <td>Bipolar Type-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patiant-04</td>\n",
       "      <td>Usually</td>\n",
       "      <td>Seldom</td>\n",
       "      <td>Usually</td>\n",
       "      <td>Most-Often</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>3 From 10</td>\n",
       "      <td>2 From 10</td>\n",
       "      <td>2 From 10</td>\n",
       "      <td>Bipolar Type-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patiant-05</td>\n",
       "      <td>Usually</td>\n",
       "      <td>Usually</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>5 From 10</td>\n",
       "      <td>5 From 10</td>\n",
       "      <td>6 From 10</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Patient Number    Sadness    Euphoric  Exhausted Sleep dissorder Mood Swing  \\\n",
       "0     Patiant-01    Usually      Seldom  Sometimes       Sometimes        YES   \n",
       "1     Patiant-02    Usually      Seldom    Usually       Sometimes         NO   \n",
       "2     Patiant-03  Sometimes  Most-Often  Sometimes       Sometimes        YES   \n",
       "3     Patiant-04    Usually      Seldom    Usually      Most-Often        YES   \n",
       "4     Patiant-05    Usually     Usually  Sometimes       Sometimes         NO   \n",
       "\n",
       "  Suicidal thoughts Anorxia Authority Respect Try-Explanation  \\\n",
       "0              YES       NO                NO             YES   \n",
       "1               YES      NO                NO              NO   \n",
       "2                NO      NO                NO             YES   \n",
       "3               YES     YES                NO             YES   \n",
       "4                NO      NO                NO              NO   \n",
       "\n",
       "  Aggressive Response Ignore & Move-On Nervous Break-down Admit Mistakes  \\\n",
       "0                  NO               NO                YES            YES   \n",
       "1                  NO               NO                 NO             NO   \n",
       "2                 YES               NO                YES            YES   \n",
       "3                  NO               NO                 NO             NO   \n",
       "4                  NO               NO                YES            YES   \n",
       "\n",
       "  Overthinking Sexual Activity Concentration  Optimisim Expert Diagnose  \n",
       "0          YES       3 From 10     3 From 10  4 From 10  Bipolar Type-2  \n",
       "1           NO       4 From 10     2 From 10  5 From 10      Depression  \n",
       "2           NO       6 From 10     5 From 10  7 From 10  Bipolar Type-1  \n",
       "3           NO       3 From 10     2 From 10  2 From 10  Bipolar Type-2  \n",
       "4          YES       5 From 10     5 From 10  6 From 10          Normal  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547329a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the dataset\n",
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cc3f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# No missing values detected. Awesome!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d1aead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete the first column in the dataframe since it is irrelevant for modelling\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be59736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The unique values for each column of the dataset\n",
    "for column in df.columns:\n",
    "    print(\"Unique values in\", column, \"are:\")\n",
    "    print(df[column].unique())\n",
    "    print('\\n')\n",
    "\n",
    "# YES value detected twice (due to extra space) in column Suicidal_thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cd6ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of values in Expert Diagnose\n",
    "df['Expert Diagnose'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da949707",
   "metadata": {},
   "source": [
    "<h2>Data Preparation</h2>\n",
    "Selecting the data that will be used for the modelling phase, cleaning any neccesary data,\n",
    "reformatting categorical data from string inputs to integers, and standardization of data scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9edc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned version of the dataframe\n",
    "clean_df = df.copy()\n",
    "clean_df.columns\n",
    "\n",
    "#Remove spaces from column names\n",
    "clean_df.columns = clean_df.columns.str.replace(' ', '_')\n",
    "clean_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28966656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rcolumn names replaced with correct spelling for better understanding\n",
    "clean_df.columns = clean_df.columns.str.replace('Sleep_dissorder', 'Sleep_disorder')\n",
    "clean_df.columns = clean_df.columns.str.replace('Anorxia', 'Anorexia')\n",
    "clean_df.columns = clean_df.columns.str.replace('Try-Explanation', 'Try_explanation')\n",
    "clean_df.columns = clean_df.columns.str.replace('Ignore_&_Move-On', 'Ignore_MoveOn')\n",
    "clean_df.columns = clean_df.columns.str.replace('Nervous_Break-down', 'Nervous_Breakdown')\n",
    "clean_df.columns = clean_df.columns.str.replace('Optimisim', 'Optimism')\n",
    "clean_df.columns = clean_df.columns.str.replace('Expert_Diagnose', 'Expert_Diagnosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92443035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#overview of the cleaned dataset\n",
    "clean_df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1b9193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra space removed in the column Suicidal_thoughts\n",
    "clean_df['Suicidal_thoughts'] = clean_df['Suicidal_thoughts'].str.replace('YES ', 'YES')\n",
    "\n",
    "#unique values for the column Suicidal_thoughts\n",
    "print(\"Unique values in Suicidal_thoughts are:\", clean_df['Suicidal_thoughts'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bf799c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#change the binary features\n",
    "clean_df.replace(('YES', 'NO'), (1, 0), inplace=True)\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4092c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#changes the categorical features of columns using likert scale\n",
    "clean_df.replace(('Usually', 'Most-Often','Sometimes','Seldom'), ('3','2','1','0'), inplace=True)\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad59f31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replaces 'From 10' in the values with nothing\n",
    "clean_df.replace('From 10', '', regex=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e465dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changes the categorical values of Expert Diagnosis to numerical values\n",
    "clean_df.replace(('Normal','Bipolar Type-1','Bipolar Type-2','Depression'),\n",
    "                 ('0','1','2','3'), inplace=True)\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463d3b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shows the distribution in percentages for all columns in a pie chart\n",
    "import matplotlib.pyplot as plt\n",
    "for column in clean_df.columns:\n",
    "    clean_df[column].value_counts().plot.pie(textprops={'fontsize': 12, 'fontweight':'bold', 'color':'white'}, autopct='%1.1f%%', figsize=(6, 6))\n",
    "    plt.title(label=column, fontsize=15, fontweight='bold', color='black')\n",
    "    plt.legend(loc='upper right', fontsize=12, title='Values', title_fontproperties ={'weight': 'bold'}, shadow=True, fancybox=True, bbox_to_anchor=(1.2, 1))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d01275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Sorts the columns by value type starting from the lowest\n",
    "sorted_columns = clean_df.columns.sort_values()\n",
    "\n",
    "#Plots the bar chart for each column\n",
    "for column in sorted_columns:\n",
    "    clean_df[column].value_counts().sort_index().plot.bar()\n",
    "    plt.title(column)\n",
    "    plt.figure(figsize=(1, 1))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01ce288",
   "metadata": {},
   "source": [
    "<h2>Data Modelling</h2>\n",
    "After preparing the data, now we'll split the data into train and test sets to evaluate the models performance\n",
    "For the model, MultinomialNB Naive Bayes (MultinomialNB) will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0934c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Split the data into independent variables (X) and dependent variable (y)\n",
    "X = clean_df.drop('Expert_Diagnosis', axis=1)\n",
    "y = clean_df['Expert_Diagnosis']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02f6052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Multinomial Naive Bayes model and trains the model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "#predictions\n",
    "y_pred = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c3cfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy score and Classification report of the model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "#accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of the model is:\", accuracy)\n",
    "\n",
    "#confusion matrix using heatmap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "heatmap_confusion = sns.heatmap(conf_matrix, annot=True)\n",
    "heatmap_confusion.set(xlabel=\"Predicted\", ylabel=\"Actual\")\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3fa3a8",
   "metadata": {},
   "source": [
    "<h4>Accuracy evaluation:</h4>\n",
    "Currently the overall model has an acceptable accuracy of 87.5%, classifying all people with a mental disorder correctly.<br>\n",
    "However, it does fail to predict some people with a 'normal' diagnosis, and classifies them as either Bipolar type-1 (1 person) or Depression (2 people).\n",
    "<br><br>\n",
    "This indicates that the model is a bit on the careful side with regards to classifying people as 'normal'. <br>\n",
    "A misdiagnoses of 'normal' could lead someone to not get the care they need, so this safety is seen as a good thing.<br>\n",
    "\n",
    "\n",
    "<h4>Discussion on accuracy score:</h4>\n",
    "Accuracy score, however, does not take into account the distribution of the data. In this case, where the diagnoses are evenly distributed, this is less of a problem.<br>\n",
    "If a representative sample were taken from the population, the distribution would shift since mental disorder prevalence is much lower in real life.<br>\n",
    "Depressive disorders in a given year only occur in 3.4% of the population and Bipolar disorder only occurs in 0.5% of the population.<br>\n",
    "Since this dataset is not representative for the total population, the F1-score should be included if the model continues to be used on a growing dataset.<br>\n",
    "Currently the F1-score, which does take the distribution of data into account, currently has a weighted average score of 86%, which is still very good.<br>\n",
    "\n",
    "\n",
    "<h4>Next steps:</h4>\n",
    "With the current data available, the accuracy of the model and the way the false prediction occur, would suit the business objective that was said out.<br>\n",
    "Now we are going to test some more models to see if the accuracy can be further improved.\n",
    "<br><br>\n",
    "\n",
    "1. Optimizing the Alpha parameter of the model:\n",
    "Using the alpha parameter to apply smoothing in Naive Bayes model to the data is something worth considering since the dataset is quite sparse with limited counts of each diagnosis.\n",
    "<br>\n",
    "\n",
    "2. Combining the disorders into a single 'abnormal' to compare against 'normal' diagnosis. In this case, since the diagnosis variable is inbalanced, the F1-score would be looked at for improvement\n",
    "<br>\n",
    "\n",
    "3. Trying more machine learning models for increased accuracy and F1-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32994880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Optimizing the Alpha parameter of the model (using GridSearchCV)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a dictionary of parameters for alpha to test in Grid Search\n",
    "param_grid = {\n",
    "    'alpha': [100, 10, 1, 0.8, 0.6, 0.4, 0.2, 0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "#Create new MultinomialNB model with alpha parameter\n",
    "nb_model2 = MultinomialNB(alpha=param_grid['alpha'])\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "nb_grid = GridSearchCV(estimator=nb_model2, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Train the model\n",
    "nb_grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "print(\"Best parameters are:\", nb_grid.best_params_)\n",
    "print(\"Best score is:\", nb_grid.best_score_)\n",
    "print(\"Best estimator is:\", nb_grid.best_estimator_)\n",
    "print(\"Best index is:\", nb_grid.best_index_)\n",
    "print(\"Scorer is:\", nb_grid.scorer_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8d1690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the new model with the best parameters\n",
    "nb_model2 = MultinomialNB(alpha=nb_grid.best_params_['alpha'])\n",
    "nb_model2.fit(X_train, y_train)\n",
    "\n",
    "y_pred2 = nb_model2.predict(X_test)\n",
    "\n",
    "# accuracy of the model\n",
    "accuracy2 = accuracy_score(y_test, y_pred2)\n",
    "print(\"Accuracy of the model is:\", accuracy2)\n",
    "\n",
    "# confusion matrix using heatmap\n",
    "conf_matrix2 = confusion_matrix(y_test, y_pred2)\n",
    "heatmap_confusion2 = sns.heatmap(conf_matrix2, annot=True)\n",
    "heatmap_confusion2.set(xlabel=\"Predicted\", ylabel=\"Actual\")\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred2))\n",
    "\n",
    "# Using GridSearchCV to optimize the model did not improve the accuracy of the model. \n",
    "# The accuracy of the model is still the same as before, since the default alpha parameter of the model is already the best parameter for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ce1a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Combining the disorders into a single 'abnormal' to compare against 'normal' diagnosis.\n",
    "\n",
    "# Combining disorders into a single 'abnormal' diagnosis\n",
    "y_train_abnormal = y_train.replace(['1', '2', '3'], '1')\n",
    "y_test_abnormal = y_test.replace(['1', '2', '3'], '1')\n",
    "\n",
    "# new Gaussian model and train the model\n",
    "nb_model_3 = MultinomialNB()\n",
    "nb_model_3.fit(X_train, y_train_abnormal)\n",
    "\n",
    "# predictions\n",
    "y_pred_3 = nb_model_3.predict(X_test)\n",
    "\n",
    "# accuracy of the model\n",
    "accuracy_3 = accuracy_score(y_test_abnormal, y_pred_3)\n",
    "print(\"Accuracy of the model is:\", accuracy_3)\n",
    "\n",
    "# confusion matrix using heatmap\n",
    "conf_matrix_3 = confusion_matrix(y_test_abnormal, y_pred_3)\n",
    "heatmap_confusion_3 = sns.heatmap(conf_matrix_3, annot=True)\n",
    "heatmap_confusion_3.set(xlabel=\"Predicted\", ylabel=\"Actual\")\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test_abnormal, y_pred_3))\n",
    "\n",
    "# The accuracy of the model is 83%, which is lower than the previous model.\n",
    "# The weighted average F1-score of the model is 0.81, which is also lower than the previous model.\n",
    "# The original model is better than the model with combined disorders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d17e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Trying more machine learning models for increased accuracy and F1-scores\n",
    "\n",
    "# Import the libaries for the classification models to test\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Create a list of models to test to use in for-loop later\n",
    "listmodels = [\n",
    "    ('Logistic Regression', LogisticRegression),\n",
    "    ('Decision Tree', DecisionTreeClassifier),\n",
    "    ('Random Forest', RandomForestClassifier),\n",
    "    ('Support Vector Machine', SVC),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier),\n",
    "    ('AdaBoost', AdaBoostClassifier)\n",
    "]\n",
    "\n",
    "# Test models and add the insights and the used setting to lists for later use\n",
    "model_results = []\n",
    "model_settings = []\n",
    "\n",
    "# Looping through the previously mentioned models to test them with original train-test split\n",
    "for model_name, model in listmodels:\n",
    "    model = model()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = classification_report(y_test, y_pred, output_dict=True)['weighted avg']['f1-score']\n",
    "    \n",
    "    # save results and settings of the model to the previously created lists\n",
    "    model_results.append((model_name, accuracy, f1))\n",
    "    model_settings.append((model_name, model.get_params()))\n",
    "\n",
    "# Print the results of the models\n",
    "for model in model_results:\n",
    "    print(model)\n",
    "\n",
    "# print the settings of the models\n",
    "for model in model_settings:\n",
    "    print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4425a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the models results in a bar chart based on accuracy and F1-scores\n",
    "\n",
    "# Create a DataFrame of the model results to use in the bar chart\n",
    "model_results_df = pd.DataFrame(model_results, columns=['Model', 'Accuracy', 'F1-Score'])\n",
    "model_results_df.set_index('Model', inplace=True)\n",
    "model_results_df.plot(kind='bar')\n",
    "\n",
    "# Add labels, titles and other styling for aesthetics\n",
    "plt.title(label='Comparison of Classification Models', fontsize=15, fontweight='bold', color='black')\n",
    "plt.xlabel('Classification Models', fontsize=12, fontweight='bold', color='black')\n",
    "plt.ylabel('Scores', fontsize=12, fontweight='bold', color='black')\n",
    "plt.legend(loc='upper right', fontsize=12, title='Scores', title_fontproperties ={'weight': 'bold'}, shadow=True, fancybox=True, bbox_to_anchor=(1.3, 1))\n",
    "\n",
    "# Show the bar chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db86e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new logistic regression model with the best parameters that came from outputs of previous model comparison\n",
    "best_model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='auto', n_jobs=None, penalty='l2', random_state=None, solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "# train the new model and make predictions\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred_lr = best_model.predict(X_test)\n",
    "\n",
    "# the accuracy of the logistic regression model and confusion matrix using heatmap\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Accuracy of the model is:\", accuracy_lr)\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "conf_matrix_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "heatmap_confusion_lr = sns.heatmap(conf_matrix_lr, annot=True)\n",
    "heatmap_confusion_lr.set(xlabel=\"Predicted\", ylabel=\"Actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e2f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare original Naive Bayes model with the Logistic Regression model\n",
    "\n",
    "# create a list of the two models that are going to be compared: the original MultinominalNB and the new Logistic Regression\n",
    "model_results = [\n",
    "    ('MultinominalNB', accuracy, classification_report(y_test, y_pred, output_dict=True)['weighted avg']['f1-score']),\n",
    "    ('Logistic Regression', accuracy_lr, classification_report(y_test, y_pred_lr, output_dict=True)['weighted avg']['f1-score'])\n",
    "]\n",
    "\n",
    "# compare the models and put the results in a bar chart\n",
    "model_results_df = pd.DataFrame(model_results, columns=['Model', 'Accuracy', 'F1-Score'])\n",
    "model_results_df.set_index('Model', inplace=True)\n",
    "model_results_df.plot(kind='bar')\n",
    "\n",
    "# Labels and other asthetic styling\n",
    "plt.title(label='Comparison of Classification Models', fontsize=15, fontweight='bold', color='black')\n",
    "plt.xlabel('Classification Models', fontsize=12, fontweight='bold', color='black')\n",
    "plt.ylabel('Scores', fontsize=12, fontweight='bold', color='black')\n",
    "plt.legend(loc='upper right', fontsize=12, title='Scores', title_fontproperties ={'weight': 'bold'}, shadow=True, fancybox=True, bbox_to_anchor=(1.3, 1))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041ef24c",
   "metadata": {},
   "source": [
    "The comparison interpretation based on results <br>\n",
    "\n",
    "Accuracy Score:<br>\n",
    "The Naive Bayes model achieved an accuracy of 87.5%, while the Logistic Regression model achieved a higher accuracy of 91.67%.<br>\n",
    "This indicates that the Logistic Regression model performed better in terms of correctly classifying the instances.\n",
    "<br><br>\n",
    "F1-score:<br>\n",
    "The Naive Bayes model had an F1-score of 86%, while the Logistic Regression model had a higher F1-score of 91.44%. <br>\n",
    "This suggests that the Logistic Regression model performed better in terms of overall model performance.\n",
    "<br><br>\n",
    "Based on these results, it can be concluded that the Logistic Regression model outperformed the Naive Bayes model in terms of accuracy, F1-score, and overall predictive performance <br>\n",
    "Therefore, the Logistic Regression model would be the preferred model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f81d0a",
   "metadata": {},
   "source": [
    "TO DO: ADD WEIYING'S MODEL TO THIS FILE AND COMPARE THIS WITH THE CHART ABOVE<br>\n",
    "TO DO: REVIEW EACH OTHER'S NOTEBOOKS<br>\n",
    "TO DO: ADD WEIYING'S MODEL TO DISCUSSION ABOVE<br>\n",
    "\n",
    "FINAL TODO: SUGGESTIONS FOR NEXT STEPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8224257",
   "metadata": {},
   "source": [
    "<h2>Suggested next steps</h2>\n",
    "\n",
    "Bart's Suggestions\n",
    "1. Implementation/deployment of the model<br>\n",
    "A use case where the model uses the responses of sign-up forms from people who contacts a psychiatrist. Based on the responses to the 17 evaluation questions that are used for predictions, the psyciatrist will have an idea of the probable mental disorder of the patient, if any. This is of course, only if the accuracy of the model is satisfactory to the psychiatrist.<br>\n",
    "2. Gathering more data<br> \n",
    "Since the current dataset is very sparse/limited, more data would help with building a more robust model for the prediction of mental disorders. This can be done through manual input into the system from new patients, for example.<br>\n",
    "3. Experiment with new classification models<br>\n",
    "The current Logistic Regression model is only one of few classification models and is the one that performs best out of the comparisons. However, this is only in the current situation. Throughout the evolution of the data set, trying different models regularly is advised."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
